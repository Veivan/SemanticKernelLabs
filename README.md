# Using Semantic Kernel, Microsoft.Extensions.AI and Ollama for chat completion service.


## ðŸ“Œ Lab1 : Using of KernelArguments and KernelFunction (plugin)

LLM doesn't use plugin - it calls manually.
## ðŸ“Œ Lab2 : Using of IChatCompletionService with Ollama client
 IChatCompletionService implementation should be prepared fr using Ollama. Function for chatting with Ollama based on information of ChatHistory prepared.
